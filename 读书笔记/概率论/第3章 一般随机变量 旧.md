## 3 一般随机变量

### 3.1 连续随机变量和概率密度函数
----

$对于随机变量X，若存在一个非负函数f_X，使得$
$$P(X \in B)=\int_Bf_X(x)dx$$

$对每一个实数轴上的集合B都成立，则称X为连续的随机变量，函数f_X就称为X的概率密度函数，或称PDF。$

$PDF的概念与离散随机变量的分布列是相对应的，。特别地，当B是一个区间的时候$
$$P(a\leq X \leq b)=\int_a ^bf_X(x)dx,$$

$$此时，这个积分可以理解为PDF和区间[a,b]所形成的曲边梯形的面积。$$

$$一个函数能够成为PDF，它必须是非负的，即f_X(x)\geq 0对一切x成立，同时它还必须满足下面的归一性条件$$

$$\int_{-\infty} ^\infty f_X(x)dx=P(-\infty < X < \infty)=1.$$


$也可以对PDF作这样的解释：对于很小的\delta，我们有$

$$P([x,x+\delta])=\int_x ^{x+\delta}f_X(x)dx \approx f_X(x) \cdot \delta,$$

$$这样，我们可以理解f_X(x)为X落入x附近的单位长度的概率。由于f_X(x)是概率律，不是某一事件的概率，$$

$故f_X(x)可以大于1.$

----
- $连续的均匀随机变量$
$$f_X(x)=\begin{cases}
    \frac{1}{b-a}, \qquad 若a\leq x\leq b,\\
    0, \qquad \quad其他，
\end{cases}$$

$$\qquad f_X(x)在[a,b]上的常数(1/(b-a))可从下面的归一化条件得到：$$

$$1=\int_{-\infty} ^\infty f_X(x)dx=\int_a ^b \frac{1}{b-a}dx.$$
- $逐段常数的PDF$
$$f_X(x)=\begin{cases}
    c_i, \qquad 若a_i \leq a_{i+1} <a_{i+1}, i=1,2,\cdots,n-1,\\
    0, \qquad 其他，
\end{cases}$$

$$\qquad 其中a_1<a_2<\cdots <a_n是常数，c_1,c_2,\cdots ,c_n是一组非负数。常数c_1,c_2,\cdots ,c_n可以像前面那样，$$

$由一组条件确定。一般说来，常数c_i必须满足下面的归一化条件：$

$$1=\int_{a_1} ^{a_n}f_X(x)dx=\sum_{i=1}^{n-1}\int_{a_i}^{a_{i+1}}c_idx=\sum_{i=1}^{n-1}c_i(a_{i+1}-a_i).$$
- $可以取任意大的值的PDF$
$$f_X(x)=\begin{cases}
    \frac{1}{2\sqrt{x}}, \qquad 若0\leq x\leq 1,\\
    0, \qquad \quad 其他.
\end{cases}$$

$$\qquad尽管在x趋于0的时候f_X(x)的值可以任意地大，f_X(x)的值可以任意地大，$$

$f_X(x)仍然是一个合法的概率密度函数。这是因为$

$$\int_{-\infty}^{\infty}f_X(x)dx=\int_0^1\frac{1}{2\sqrt{x}}dx=\sqrt{x} |_0^1=1.$$


----
**关于PDF性质的小结**

$设X的PDF(概率密度函数)为f_X(x).$
- $f_X(x) \geq 0对一切x成立。$

$$\int_{-\infty}^\infty f_X(x)dx=1$$

- $设\delta是一个充分小的正数，则P([x,x+\delta])\approx f_X(x) \cdot \delta.$
- $对任何实数轴上的子集B，$
$$P(x \in B)=\int_B f_X(x)dx.$$

----
#### 3.1.1 期望
$连续随机变量X的期望或均值是由下式定义的：$
$$E[X]=\int_{-\infty}^\infty xf_X(x)dx.$$



。。。。。
$$随机变量X的n阶矩定义为E[X^n]随机变量X的方差定义为随机变量(X-E[X])^2的期望，记为var(X).$$

----
**连续随机变量的期望的性质**

$记X为连续随机变量，其相应的PDF(概率密度函数)为f_X(x).$

- $X的期望由下式定义：$

$$E[X]=\int_{-\infty}^\infty xf_X(x)dx.$$

- $关于随机变量g(X)的期望规则为：$
$$E[g(X)]=\int_{-\infty}^\infty g(x)f_X(x)dx.$$

- $X的方差由下式给出：$
$$var(X)=E[(X-E[X])^2]=\int_{-\infty}^\infty(x-E[X])^2f_X(x)dx.$$

- $关于方差，下列公式成立：$
$$0\leq var(X)=E[X^2]-(E[X])^2.$$
- $设Y=aX+b，其中a和b为常数，则$
$$E[Y]=aE[X]+b, \qquad var[Y]=a^2var(X).$$

----
#### 3.1.2 指数随机变量
$若随机变量X的PDF具有下列形式：$
$$f_X(x)=\begin{cases}
 \lambda e^{-\lambda x}, \qquad 若x\geq 0,\\
 0, \qquad \qquad 其他，
\end{cases}$$

$$则称X是指数随机变量，其中\lambda是分布的参数，\lambda >0。这个函数是合法的概率密度函数，其原因是$$

$$\int_{-\infty}^\infty f_X(x)dx=\int_0^\infty \lambda e^{-\lambda x}dx=-e^-|_0^\infty=1.$$

$$注意，指数分布具有这样的特性：X超过某个值的概率，随着这个值的增加而按指数递减，即对于任意a \geq 0,$$

$$P(X\geq a)=\int_a ^\infty \lambda e^{-\lambda x}dx=-e^{-\lambda x}|_a^\infty=e^{-\lambda a}.$$

$指数随机变量具有广泛的用处，它可以表示到发生某个事件为止所用的时间，$

$$例如，这个事件可以是某条信息到达计算机、一台仪器的使用寿命终止、一个灯泡用坏了或一辆汽车出车祸等。$$

$我们将会看出，指数随机变量与离散的几何随机变量十分相似。$
$几何随机变量也与某一个我们感兴趣的事件发生的(离散事件相关联)。$

----
**指数随机变量的均值和方差**

$$E[X]=\frac{1}{\lambda}, \qquad \qquad var(X)=\frac{1}{\lambda^2}.$$

$这些公式可以直接计算得到，利用分部积分法，$
$$E[X]=\int_0^\infty x\lambda e^{-\lambda x}dx$$

$$\qquad \qquad \qquad \qquad=(-xe^{-\lambda x})|_0^\infty +\int_0^\infty e^{-\lambda x}dx$$

$$\qquad =0-\frac{e^{-\lambda x}}{\lambda}|_0^\infty$$

$$=\frac{1}{\lambda}.$$
$再利用分部积分法，可得到X的二阶矩$
$$E[X^2]=\int_0^\infty x^2\lambda e ^{-\lambda x}dx$$

$$\qquad \qquad \qquad \qquad \qquad =(-x^2e^{-\lambda x})|_0^\infty + \int_0^\infty 2xe^{-\lambda x}dx$$

$$\qquad =0+\frac{2}{\lambda}E[X]$$

$$=\frac{2}{\lambda^2}$$

$最后，利用公式var(X)=E[X^2]-(E[X])^2，得到$
$$var(X)=\frac{2}{\lambda^2}-\frac{1}{\lambda^2}=\frac{1}{\lambda^2}.$$

----
### 3.2 分布函数
$$我们分别分布列(离散情况)和概率密度函数(连续情况)来刻画随机变量X的取值规律。$$

$$现希望用一个统一的数学工具来刻画随机变量的取值规律。分布函数(用记号CDF表示简称)就能完成这个任务。$$

$$随机变量X的CDF是x的函数F_X，对每一个x，F_X(x)定义为P(X\leq x).特别地，当X为离散或连续的情况下，$$

$$F_X(x)=P(X\leq x)=\begin{cases}
    \sum_{k \leq x}P_X(k), \qquad 若X是离散的， \\
    \int_{-\infty}^x f_X(t)dt, \qquad 若X是连续的.
\end{cases}$$

$分布函数又称为累积分布函数，累积意味着F_X(x)将X取值的概率由-\infty累计到x.$

$$在一个概率模型中，随机变量可有不同的类型，可以是离散的，可以是连续的，甚至可以是既非离散也非连续的。$$

$$但不管是什么类型的随机变量，它们有一个共同的特征，即都有一个分布函数，这是因为{X \leq x}的概率的，$$

$都称为随机变量X的概率律。因此离散情况下的分布列，连续情况下的概率密度函数以及一般情况下的分布函数$
$都是相应的随机变量的概率律。$

- $某些离散随机变量的CDF的分布函数：$

$$F_X(x)=P(X\leq x)=\sum_{k\leq x}P_X(k).$$

- $某些连续随机变量的CDF的分布函数：$

$$f_X(x)=\frac{dF_X}{dx}(x).$$

$对于连续随机变量，CDF是连续的。$

----
**CDF的性质**
$$随机变量{X}的CDF，F_X由下式定义，对每一个x，F_X(x)=P(X\leq x),并且F_X具有下列性质。$$

- $F_X是单调非减函数：$
$$若x\leq y，则F_X(x) \leq F_X(y).$$

- $当x \to -\infty的时候，F_X(x)趋于0，当x\to \infty的时候，F_X(x)趋于1.$
- $当X是离散随机变量的时候，F_X(x)为x的阶段函数。$
- $当X是连续随机变量的时候，F_X(x)为x的连续函数。$
- $当X是离散随机变量并且取整数值时，分布函数和分布列可以利用求和或差分互求：$
$$F_X(k)=\sum_{i=-\infty}^kp_X(i).$$

$$P_X(k)=P(X\leq k)-P(X \leq k-1)=F_X(k)-F_X(k-1),$$

$其中k可以是任意整数。$

- $$当X是连续随机变量的时候，分布函数和概率密度函数可以利用积分或微分互求：$$
  
$$F_X(x)=\int_{-\infty}^xf_X(t)dt, \qquad f_X(x)=\frac{dF_X}{dx}(x).$$

$第二个等式只在分布函数可微的那些点上成立。$



----
### 3.3 正态随机变量
$一个连续随机变量X称为正态或高斯的，若它的概率密度函数具有下列形式：$

$$f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-(x-\mu)^2/(2\sigma^2)},$$

$$其中\mu和\sigma是概率密度函数的两个参数，\sigma还必须是正数。可以证明f_X(x)满足下面的概率密度函数的归一化条件$$

$$\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^\infty e^{-(x-\mu)^2/(2\sigma^2)}dx=1$$

$正态随机变量的均值和方差可由下式给出$
$$E[X]=\mu， \qquad var(X)=\sigma^2.$$

$$由于X的概率密度函数相对于\mu对称，其均值只能是\mu。至于方差，依定义它由下式给出$$

$$var(X)=\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^\infty (x-\mu)^2e^{-(x-\mu)^2/(2\sigma^2)}dx.$$

$将公式中的积分作积分变量替换y=(x-\mu)/\sigma以及分部积分，得到$
$$var(X)=\frac{\sigma^2}{\sqrt{2\pi}}\int_{-\infty}^\infty y^2e^{y^2/2}dy$$

$$\qquad \qquad \qquad \qquad \qquad \qquad =\frac{\sigma^2}{\sqrt{2\pi}}(-ye^{-y^2/2})|_{-\infty}^\infty + \frac{\sigma^2}{\sqrt{2\pi}}\int_{-\infty}^\infty e ^{-y^2/2}dy$$

$$\qquad =\frac{\sigma^2}{\sqrt{2\pi}}\int_{-\infty}^\infty e^{-y^2/2}dy$$

$$=\sigma^2$$

$上面最后的等式是由于$
$$\frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty e^{-y^2/2}dy=1.$$

$$这个公式是当\mu =0和\sigma^2=1的时候的正态随机变量的概率密度函数的归一化条件。$$

----
**线性变换之下随机变量的正态性保持不变**

$$设X是正态随机变量，其均值为\mu ，方差为\sigma^2。若a\neq 0和b为两个常数，则随机变量$$

$$Y=aX+b$$

$仍然是正态随机变量，其均值和方差由下式给出：$
$$E[Y]=a\mu +b, \qquad var(Y)=a^2\sigma^2.$$

----
**标准正态随机变量**
$$设正态随机变量Y的期望为0，方差为1，则Y称为标准正态随机变量。以\Phi 记它的CDF：$$

$$\Phi(y)=P(Y \leq y)=P(Y < y)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^y e^{-t^2/2}dt.$$

$$通常将它的值列成一个表，这是计算有关正态随机变量的概率的重要工具。$$

----
### 3.4 多个随机变量的联合概率密度
$$非负放入二元函数f_{X,Y}(x,y)称为X和Y的联合概率密度函数，如对任意的平面上的二元集合B，下式成立：$$

$$P((X,Y)\in B)=\int_{(x,y)|\in B}\int f_{X,Y}(x,y)dxdy.$$

$$上式的积分是二重积分，积分区域为B。特别地，若B={(x,y)|a \leq x \leq b,c\leq y \leq d}，则上式变成$$

$$P(a \leq X \leq b,c \leq Y\leq d)=\int_c^d \int_a ^b f_{X,Y}(x,y)dxdy.$$

$进一步，若令B为全部二维平面，就可以得到密度函数的归一化条件$

$$\int_{-\infty}^\infty \int_{-\infty}^\infty f_{X,Y}(x,y)dxdy=1.$$

$$为解释联合概率密度函数的意义，取\delta为一个充分小的正数，考虑(X,Y)落入一个小方块内的概率$$

$$P(a \leq X \leq a+\delta, c\leq Y \leq c+\delta)=\int_c ^{c+\delta} \int_a^{a+\delta}f_{X,Y}(x,y)dxdy \approx f_{X,Y}(a,c) \cdot \delta^2$$

$我们可以将f_{X,Y}(a,c)看成(X,Y)落入(a,c)附近单位面积中的概率。$

$$联合概率密度函数包含了所有关于(X,Y)的取值概率的信息，包括它们之间的相互依赖的信息。$$

$利用它。我们可以计算任何由(X,Y)所刻画的事件的概率/作为特殊情况，$
$我们可以计算单独一个随机变量(X或Y)所刻画的事件的概率。$

$例如，令A为一个实数的集合，考虑事件 \{X\in A\}，我们有：$
$$P(X\ in A)=P(X \in A,Y\in (-\infty,\infty))=\int_A \int_{-\infty}^\infty f_{X,Y}(x,y)dydx.$$

$与下面的公式比较$
$$P(X \in A) = \int_A f_X(x)dx,$$

$就可以知道，X的边缘概率密度函数由下式给出：$
$$f_X(x)=\int_{-\infty}^\infty f_{X,Y}(x,y)dy.$$

$类似地可得：$
$$f_Y(y)=\int_{-\infty}^\infty f_{X,Y}(x,y)dx.$$

----
#### 3.4.1 联合分布函数
$设X和Y是在同一个试验中的两个随机变量。我们定义它们的联合分布函数为：$
$$F_{X,Y}(x,y)=P(X\leq x, Y\leq y).$$

$与一个变量的分布函数一样，它既适用于离散随机变量，也适用于连续随机变量。$
$特别地，若X,Y具有联合概率密度函数(简称联合PDF)f_{X,Y}，则$

$$F_{X,Y}(x,y)=P(X \leq x,Y \leq y)=\int_{-\infty}^x \int_{-\infty}^yf_{X,Y}(s,t)dtds.$$

$反过来，联合概率密度函数也可以从联合分布函数通过求微商得到：$
$$f_{X,Y}(x,y)=\frac{\vartheta^2 F_{X,Y}}{\vartheta x \vartheta y}(x,y).$$

----

#### 3.4.2 期望
$设X和Y为联合随机变量，g是一个函数，则Z=g(X,Y)也是一个随机变量。$
$此时计算期望的期望规则仍然有效，因此：$

$$E[g(X,Y)]=\int_{-\infty}^\infty \int_{-\infty}^\infty g(x,y) f_{X,Y}(x,y)dxdy.$$

$作为一种重要的特殊情况，对于常数a,b,c，我们有$
$$E[aX+bY+c]=aE[X]+bE[Y]+c.$$

----
#### 3.4.3 多于两个随机变量的情况
$$三个随机变量X、Y、Z的联合概率密度函数的定义与两个随机变量的情况是完全相似的，例如，满足条件：$$

$$P((X，Y，Z)\in B)=\int_{(x,y,z)\in B}\int_{X,Y,Z}(x,y,z)dxdydz (B为任意三元集合)$$
$的非负函数f_{X,Y,Z}(x,y,z)就是X、Y、Z的联合概率密度函数。下列类型的关系都是成立的：$
$$f_{X,Y}(x,y)=\int_{-\infty}^\infty f_{X,Y,Z}(x,y,z)dz,$$

$$f_x(x)=\int_{-\infty}^\infty \int_{-\infty}^\infty f_{X,Y,Z}(x,y,z)dydz.$$

$计算随机变量g(X,Y,Z)的期望的规则是$
$$E[g(X,Y,Z)]=\int_{-\infty}^\infty \int_{-\infty}^\infty \int_{-\infty}^\infty g(x,y,z)f_{X,Y,Z}(x,y,z)dxdydz,$$

$若g是一个线性函数aX+bY+cZ，则$
$$E[aX+bY+cZ]=aE[X]+bE[Y]+cE[Z].$$

$$若涉及的随机变量的个数多于三个，相应的改变是明显的。例如，对于随机变量X_1, X_2,\cdots, X_n，我们有$$

$$E[a_1X_1 +a_2X_2+\cdots+ a_nX_n]=a_1E[X_1]+a_2E[X_2]+\cdots+a_nE[X_n]$$

-----
**多元连续随机变量性质的小结**

$令X和Y为联合连续随机变量，其联合概率密度函数为f_{X,Y}.$
- $利用联合概率密度函数可以进行概率计算：$

$$P((X,Y)\in B)=\int_{(x,y) \in B} \int f_{X,Y} (x,y) dxdy.$$

- $X和Y的边缘概率密度函数可利用联合概率密度函数进行计算得到：$
$$f_X(x)=\int_{-\infty}^\infty f_{(X,Y)}(x,y)dy, \qquad f_Y(y)=\int_{-\infty}^\infty f_{(X,Y)}(x,y)dx.$$

- $$联合分布函数由公式F_{X,Y}(x,y)=P(X \leq x,Y \leq y)定义，并且，在联合概率密度函数的连续点上，$$

$下面的公式成立：$

$$f_{X,Y}(x,y)=\frac{\vartheta^2 F_{X,Y}}{\vartheta x \vartheta y}(x,y).$$

- $X和Y的函数，g(X,Y)定义了一个新的随机变量，并且$
$$E[g(X,Y)]=\int_{-\infty}^\infty \int_{-\infty}^\infty g(x,y)f_{X,Y}(x,y)dxdy. $$

$若g是一个线性函数aX+bY+c，则$
$$E[aX+bY+c]=aE[X]+bE[Y]+c.$$

- $上面的结论能够很自然地推广到多于两个随机变量地情况。$
----
### 3.5 条件
>与离散随机变量的情况相似，可以以一个随机事件或另一个随机变量为条件，讨论随机变量的特性，并在此基础上建立条件概率密度函数和条件期望的概念。各种定义和公式都与离散的情况平行，且其意义的解释也都是类似的。在连续情况下，还会遇到以零概率事件{Y=0}为条件的情况，这在离散情况下是无法处理的。

----
#### 3.5.1 以事件为条件的随机变量
$$一个连续随机变量X在给定事件A(P(A)>0)发生的条件下的条件概率密度函数f_{X|A}(x)是这样定义的：$$

$它是一个非负函数，并且对一切直线上的集合B，满足：$

$$P(X \in B|A)=\int_B f_{X|A})(x)dx.$$

$特别地，当B取成全部实数集合的时候，得到归一化等式$
$$\int_{-\infty}^\infty f_{X|A}(x)dx=1,$$

$这说明f_{X|A}是一个合格的概率密度函数。$
$$当我们将事件A取成{X \in A}的形式以后(P(X \in A)>0)，由条件概率的定义得到$$

$$P(X \in B|X \in A)=\frac{P(X \in A, x \in B)}{P(X \in A)}=\frac{\int_{A \cap B}f_X(x)dx}{P(X\in A)}.$$
$将这个式子与前面的关于条件概率密度函数的定义比较，可知$
$$\int_{X|A}(x)=\begin{cases}
    \frac{f_X(x)}{P(X \in A)}, \qquad 若x \in A, \\
    0, \qquad  \qquad \quad 其他.
\end{cases}$$

$与离散情况相同，条件概率密度函数在条件集合外边的取值为0.在条件集合内部，$
$条件概率密度函数与无条件概率密度函数具有相同的形状，$
$唯一的差别是条件概率密度函数还有一个归一化因子1/P(X \in A).$
$归一化因子1/P(X \in A)使得f_{X|A}(x)的积分为1，从而f_{X|A}(x)成为一个合格的概率密度函数。$
$这样，条件概率密度函数。这样，条件概率密度函数与通常的概率密度函数一样，$
$不过它将已经发生的事件{X \in A}作为随机试验的全空间。$

----
**以事件为条件的条件概率密度函数**

。。。。。。


----
#### 3.5.2 一个随机变量对另一个随机变量的条件
$$设X和Y为联合连续随机变量，其联合概率密度函数为f_{X,Y}(x,y).对任何满足f_Y(y)>0的y值，$$

$在给定Y=y的情况下，X的条件概率密度函数由下式定义：$

$$f_{X|Y}(x|y)=\frac{f_{X,Y}(x,y)}{f_Y(y)}$$

$$这个定义与离散情况下的公式P_{X|Y}=P_{X,Y} (x,y)/P_Y(y)完全相似。$$

$$在考虑条件概率密度函数的时候，最好将y值固定下来，并将f_{X|Y}(x|y)看成x的函数。$$

$$作为x的函数，条件概率密度函数f_{X|Y}(x|y)与联合概率密度函数f_{X,Y}(x,y)具有相同的形状，$$

$$这是因为它们仅相差一个与x无关的常数因子f_Y(y)。另外，$$

$f_Y(y)=\int_{-\infty}^\infty f_{X,Y}(x,y)dx$

$暗示了归一化性质：$
$$\int_{-\infty}^\infty f_{X|Y}(x|y)dx=1$$

$所以，对任何固定的y值，f_{X|Y}(x|y)是一个合格的概率密度函数。$

----
**以另一个随机变量为条件的条件概率密度函数**
。。。。。。


----



#### 3.5.3 条件期望
$$对于连续随机变量X，给定事件A的条件期望E[X|A]的定义与无条件期望的定义相似，$$

$不过我们现在利用条件概率密度函数f_{X|A}来定义。$
$$类似地，条件期望E[X|Y=y]是通过条件概率密度函数f_{X|Y}进行定义的。$$

$关于期望的各种性质可以原封不动地搬到条件期望中来。$

$$要注意的是，此处所有的公式与离散情况的公式是完全相似的，只是将离散情况下的求和号变成积分号，$$

$分布列改成概率密度函数。$

----
**条件期望性质的小结**

$记X和Y为联合连续随机变量，A是满足P(A)>0的事件。$
- $X在给定事件A之下的条件期望由下式定义$

$$E[X|A]=\int_{-\infty}^\infty xf_{X|A}(x)dx,$$

$给定Y=y之下的条件期望由下式定义：$
$$E[X|Y=y]=\int_{-\infty}^\infty xf_{X|Y}(x|y)dx.$$

- $期望规则仍然有效：$
$$E[g(X)|A]=\int_{-\infty}^\infty g(x)f_{X|A}(x)dx, $$

$$E[g(X)Y=y]=\int_{-\infty}^\infty g(x)f_{X|Y}(x|y)dx. $$
- $$全期望定理：设A_1,A_2,\cdots,A_n为互不相容的n个事件，对每个i，P(A_i)>0，$$

$并且这些事件形成样本空间的一个分割，则$

$$E[X]=\sum_{i=1}^nP(A_i)E[X|A_i].$$

$相似地，$
$$E[X]=\int_{-\infty}^\infty E[X|Y=y]f_Y(y)dy.$$

- $涉及几个随机变量的函数的情况，具有完全相似的结果，例如$
$$E[g(X,Y)|Y=y]=\int g(x,y)f_{X|Y}(x|y)dx,$$

$$ \quad E[g(X,Y)]=\int E[g(X,Y)|Y=y]f_Y(y)dy.$$

----
**验证全期望公理**

两个全期望定理的公式

。。。。。。

----

#### 3.5.4 独立性

$$与离散的情况完全相似，若两个连续随机变量X和Y的联合概率密度函数是它们各自的边缘概率密度函数的乘积，即$$

$$f_{X,Y}(x,y)=f_X(x)f_Y(y)对一切x和y成立,$$

$$则称X和Y相互独立。比较公式f_{X,Y}(x,y)=f_{X|Y}(x|y)f_Y(y)可知，独立性条件与下式是等价的：$$

$$f_{X|Y}(x|y)=f_X(x)对一切x和满足f_Y(y)>0的y成立.$$

$基于对称性，下列条件也与独立性条件等价：$
$$f_{Y|X}(y|x)=f_Y(y)对一切y和满足f_X(x)>0的x成立。$$

$$自然地，两个随机变量的相互独立性的概念可以推广到多个随机变量的相互独立性。$$

$$例如设X、Y、Z为三个联合连续随机变量。若它们的联合概率密度函数具有下面的表达式$$

$$f_{X,Y,Z}(x,y,z)=f_X(x)f_Y(y)f_Z(z)对一切x、y、z成立，则称它们是相互独立的。$$

----
$$若X和Y相互独立，则任何两个形如{X \in A}和{Y \in B}的事件是相互独立的。事实上，$$

$$P(X \in A 且 Y \in B)=f_{x \in A}f_{x \in B}f_{X,Y}(x,y)dydx$$

$$\qquad \qquad  \qquad  \qquad \qquad =\int_{x \in A}\int_{y \in B} f_X(x) f_Y(y)dydx$$

$$\qquad \qquad  \qquad  \qquad \qquad=\int_{x \in A}f_X(x)dx \int_{y \in B}f_Y(y)dy$$

$$\qquad \qquad  \qquad  \qquad=P(X \in A)P(Y \in B).$$

$特别地，独立性蕴涵$
$$F_{X,Y}(x,y)=P(X \in x,Y \in y)=P(X \leq x)P(Y \leq y)=F_X(x)F_Y(y).$$
$性质F_{X,Y}(x,y)=F_X(x)F_Y(y)对一切x和y成立$

$$可以作为两个随机变量相互独立的一般定义，即使是X为离散，Y为连续的情况，这个定义也是适用的。$$
$$相似于离散的情况，可以证明：若X与Y相互独立，则对任意函数g和h，下式成立：$$

$$E[g(X)h(Y)]=E[g(X)]E[h(Y)].$$

$最后，独立随机变量之和的方差等于它们的方差之和。$

----
**连续随机变量的相互独立性**

$令X和Y为联合连续随机变量$
- $$若f_{X,Y}(x,y)=f_X(x)f_Y(y)对一切x和y成立，则X和Y相互独立。$$

- $若X和Y相互独立，则E[XY]=E[X]E[Y].$

$$\qquad 进一步地，对于任意函数g和h，随机变量g(X)和h(Y)也是相互独立的，于是$$

$$E[g(X)h(Y)]=E[g(X)]E[h(Y)].$$

- $若X和Y相互独立，则var(X+Y)=var(X)+var(Y).$

----
### 3.6 连续贝叶斯准则
。。。。。。

----
### 3.7 小结和讨论
。。。。。。